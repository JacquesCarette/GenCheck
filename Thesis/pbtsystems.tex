The previous chapter developed 
a formal definition for a property based test of a specification,
and a formal argument for program correctness 
using the evidence from such tests with supporting hypotheses.
This chapter uses these definitions as the basis for
an overview and critique of some existing property based testing systems.
Three generally contrasting approaches to property based testing are considered:

\begin{enumerate}
\item assertion based testing;
\item tools that analyze the specification and / or implementation to 
either derive minimal test contexts or ensure minimal coverage of the code by the test;
\item tools that use sampling methodologies 
and generic programming strategies to 
automatically generate test suites.
\end{enumerate}
\noindent
This last category,
which includes \QC (\cite{Claessen2000}) and related testing packages,
is the focus of the thesis
and so will receive a more comprehensive treatment.
The first two categories have been addressed 
to highlight alternatives to interface based \pbt.

\section{Assertion Based Testing }
\gordon{ Does this add anything?  I never really refer back to this section.}
In assertion based testing (\cite{Hoare1969}),
invariants and pre and post conditions from the formal specification
are inserted directly into the implementation as executable \emph{assertions}.
Assertions are conditional statements that are evaluated at run time, 
raising an exception and terminatng if the assertion fails
\footnote{These assertions are not to be confused with 
the supporting hypotheses of a test context,
which is not part of the test program.}.
The process of translating the axioms of the specification 
into assertions for run-time checking is 
similar to that for properties in a property based test.
This is also called \emph{design by contract},
because the invariants and pre/post conditions form a ``contract'' to be fulfilled by each operation.

Assertions  are part of the implementation,
while in other forms of \pbt the properties are 
in an independent test program entirely separate from the implementation.
This results in a number of differences between the two styles:

\begin{enumerate}
\item embedding the assertions in the code ensures programmers will 
see the pre/post conditions and invariants as they work,
while for property based testing these are (usually) in separate modules;
\item properties can only reference 
their input arguments and the components of the specification
but assertions can also incorporate the implementation's \emph{internal state} values;
\item assertion test cases are generated by the regular use of the system,
while test cases must be separately generated for property based testing
\item in some programming languages (e.g. Java),
assertion statements can also be used for error handling,
blurring the line between testing and regular use
\item assertions either continue to incur 
run-time checking costs during regular operations,
or a version of the system without the run-time checks must be produced,
weakening the value of the testing and possibly introducing errors.
\item If the assertions are dependent on persistent internal state variables,
the testing must be designed in such a way as to indirectly manipulate those values,
which may be challenging.
\end{enumerate}

\subsection{Example: xUnit framework}

The xUnit test framework (\url{http://sourceforge.net/projects/xunit/})is 
a language independent interface to support assertion based testing.
Originally based on the work of Kent Beck for the Smalltalk language
(\url{http://www.xprogramming.com/testfram.htm}),
variants of xUnit have been implemented for a number of languages, 
including JUnit for Java and HUnit for Haskell.

Test cases are written in 
the native language of the module or program to be tested,
using the language specific implementation of 
the xUnit interface to implement the assertions.
The programming interface supplies functions to initialize and clean up
the underlying state of the system before each test.
A test is successful if it does not throw an exception,
and any reporting of the successful test cases must be
provided by the test developer,
or observed directly from the test program source.

xUnit is useful for repeating tests and testing across multiple platforms.
Combined with a source code repository (such as GitHub or SVN) it
can also be used to share test programs between project participants.
It does not, however,  assist in developing the test cases or provide any information 
about test coverage other than identifying the failing test case that caused the exception to be raised.

\subsection{Eiffel}
\gordon{If this section gets left in, then I need to review how Eiffel enforces program correctness based on the specification, and mention that here.}

Eiffel (\url{www.eiffel.com}) is a programming language built around 
the ``design by contract'' programming paradigm.
Pre-conditions, post-conditions and invariants 
are explicitly defined in the language as part of the class definition
(Eiffel is also object oriented).
Sub-classes inherit these conditions and invariants,
and can only modify them to weaken pre-conditions
and strengthen post-conditions (invariants of the superclass must be respected).
These conditions and invariants are labelled 
with unique names for tracking purposes.
Unlike the xUnit example,
the different kinds of assertions are clearly distinguished in Eiffel,
and specifications are clearly distinguished from error handling.


\section{Integrating Static Analysis and Test Systems}

Static analysis refers to the examination of 
the specification or implementation of a system
to determine an optimal test set.
Theorem provers may be used both to 
identify a decomposition of the property's domain
into equivalence classes (page \pageref{sub:uniformity}),
and proofs supporting that decomposition.
Code analyzers examine what parts of the implementation
(source code, state variables, conditions) are executed during a test
to ensure a minimal coverage of the implementation's components,
for example ensuring that every line of code or each branch is run at least once.
This analysis can be done independently,
but some test systems have incorporated these concepts
to validate the test data set or even generate the test cases.

Both of these approaches provide a useful insight into the value of a test.
However, as noted in section \ref{swtest}, 
the value of a specification analysis must 
always be viewed with some skepticism
due to the differences between the idealized program and
the real world systems that implement it:
\cite{JacksonDamon1996} noted that ``good provers tend to be bad refuters''.
Code analyzers are particularly useful for 
ensuring implementation details not addressed by the specification
are covered by the test,
but are specific to an implementation and may not be applicable
to any modifications to that code.
Despite these limitations,
these approaches can be useful as one part of a testing strategy,
and can be incorporated into \emph{stratified sampling} methods.

\subsection{Example: \DAISTS}\label{sub:DAISTS}

The Data Abstraction, Implementation, Specification and Testing System (\DAISTS) (\cite{GannonEtAl1981})
was one of the earliest property based testing tools,
and also incorporated code analysis to evaluate the test.
It allows the algebraic specification of an abstract data type
to be augmented with axioms written in the \DAISTS specification language,
and set of test values for each of the axioms.
The implementation (the data type representation and methods),
the specification axioms and the test cases (``test points'') are stored in the same source file,
which is compiled into a test program (``test driver'')
that evaluates each property over each test point.
The coded axioms are written as boolean valued properties,
and express an equality relation between 
the composition of two or more functions and an expression.

The authors stress that successful tests provide 
limited confidence in program correctness,
and that this confidence is directly associated with test coverage.
Since the test points were manually written by the test developer,
\DAISTS implements structural test criteria
to analyze the implementation and test values to ensure:
\begin{itemize}
\item all lines of code in the method implementations are executed in the property test
\item all branch conditions in the axiom are evaluated
\item all sub-expressions and variables in the implementation and axioms also change 
at some point during each test
\end{itemize}
\noindent This attention to test coverage,
as opposed to the mechanics of defining and evaluating the tests,
is a distinctive feature of \DAISTS.

The strength of this system was in providing the specification as 
a collection of mechanically verifiable properties and test cases that
the implementation must satisfy.
In general, they concluded that 
testing with \DAISTS avoided common errors in writing test programs,
and that it did not take any longer to write the modules with \DAISTS because
the additional time was offset by not having to debug the test programs.
In particular , their case study suggested that the structural analysis of the axioms and implementations
forced the participants to include boundary and extraordinary cases in their tests,
which was shown to be productive in finding errors.
The authors noted two weaknesses: axioms were limted to equalities where 
the left hand side was a composition of functions,
and the implementation had to be complete
instead of allowing parts of the specification to be tested independently.

\subsection{Example: \HOLTG }

\emph{\HOLTG} (\cite{Brucker2012}) is an interactive tool for 
automatically generating test cases for a property written in higher order logic (HOL).
It uses the Isabelle/HOL theorem prover to 
partition the property's domain into equivalence classes (section \ref{sub:uniformity}),
and then creates and runs a test case for each.
It also explicitly creates the regularity, uniformity and independence hypotheses
\footnote{A test is \emph{independent} if the result is independent of the order of the test cases.})
from the proof strategies used by Isabelle/HOL to obtain the equivalence classes.
Concrete representatives for each of the classes
are generated and written into a test script,
which is compiled into a test program consisting of:

\begin{itemize}
\item the program to be tested,
\item a test script (written in SML) containing 
the test data and the specification as a computable predicate (the oracle)
\item and a driver that provides an interface between
the program and the compiled test script.
\end{itemize}

The test execution is encapsulated in a \emph{state error monad},
with each test evaluated in turn maintaining any necessary state,
and interrupting execution if a test fails.
The test driver makes use of the foreign language interfaces of SML
to allow calls to programs written in many different languages.

The authors state as a theorem that  \HOLTG is a complete testing procedure:

\begin{theorem}

$$TS \implies TC_1 \land \cdots  \land TC_n \land H_1 \land \cdots \land H_n$$

where $TC_i$ are the test cases and $H_j$ are the hypotheses.
\end{theorem}

\noindent The  approach of developing a customized  \emph{test hypothesis} to 
explicitly address details of the property being tested
\footnote{The authors use the colorful term ``logical massage'' to describe this process.}
was based on \cite{Gaudel1995},
and results in a specific version of the kind of 
test theory described in section \ref{formal_spec}.
The Isabelle/HOL theory library is extended with this test theory,
which models the application domain using conservative extensions,
so the resulting \emph{test context} (section \ref{sub:context}) is a formally correct test plan.

\HOLTG provides an good starting point for generating test cases,
ensuring that all of the identified subdomains of each property are tested at least once.
This approach also guarantees the test specification is sound and
provides an explicit, customized version of the test hypotheses
to create a verifiable, formal, proof of correctness.
Although only one representative from each subdomain is created and tested,
the authors note that the process required to generate the test cases
can be quite long.
This approach is well suited for systems that are near ideal,
but the heavy dependency on the equivalence classes of the program,
based solely on the specification,
makes the correctness argument fragile in a real world environment.

\section{Sampling Generators: The *Check Family}\label{sec:samplegens}

Sampling \pbt systems automatically generate large test data sets
from the definition of the property's domain,
without analysis of the specification or implementation.
A collection of software test packages that use different sampling methodologies
were developed for use by the functional language community.
Even though this approach produces test cases of lower value
than the more sophisticated static analysis based approaches,
many more test cases can be generated and evaluated with
significantly less effort from the test developer.

\QC  (\citep{Claessen2000} is a popular \pbt tool for Haskell
that automatically generates random test cases.
A number of other similar packages were
based on \QC (or developed concurrently):

\begin{description}
\item[\SC (\citep{Runcimanetal2008}) ] exhaustively generates all test cases up to the requested size;
\item[GAST (\cite{GAST2002})],  developed concurrently with \QC,
uses exhaustive test case generation but randomly orders the values
and truncates the test case sequence at a specified number of cases;
\item[\EC (\cite{EasyCheck2008}] generates test cases using a
``randomized, diagonal traversal'' to balance small and large algebraic data structures in the test suite;
\item[feat (\cite {Duregard2012}] (developed concurrently with \GC) 
provides efficient enumerations of Haskell types to support exhaustive, uniform interval and random sampling.
\end{description}

A quick note: throughout this chapter and the remainder of the thesis,
the uniformity and probabilistic nature of the ``random'' generators 
provided by software libraries such as Haskell's will be accepted
as sufficiently random for the purposes of test case generation
without further discussion.

This work is largely inspired by and based on the \QC family of testing packages,
and so they are discussed at length there.
This discussion will include comparisons of their test selection strategy,
but will also delve into the architecture and design of the packages:
user interface, property definition, test case generation, test case evaluation, termination conditions and reporting capabilities.
The design of the \GC package presented in chapter \ref{chap:GCimplement} 
resulted from this analysis.

\subsection{QuickCheck}\label{sub:quickcheck}

\QC has become the de facto testing platform in the Haskell community,
and the standard for testing publicly released Haskell packages 
through the Hackage library (\url{www.hackage.haskell.org}).
As such, a critique and comparison of \QC and the other related packages
will be useful for establishing the requirements for 
automated test case generation for property based testing.
\QC will be described in depth
as many of the features of the other packages are either 
derived from or in response to that package;
the others will receive a more cursory review.
It is assumed the readers are somewhat familiar with these packages;
those unfamiliar and interested in them should consult the original papers 
as many otherwise important details have been omitted.
In particular, this analysis was based on early version of \QC (1.2.0.0) and
does not reflect the current state of this project.

\subsubsection{Specification and Properties}
\QC is a property based testing tool for Haskell modules,
generating \emph{random} test values 
based on the input type of a property.
More formally, given a function |f| over a data-type |a|, 
equipped with a \emph{generator} of random instances of |a|,
and a property | p | relating | a | and |f a| for all | a |, 
\QC will verify that | p | holds over a ``random'' sample of values of | a |.
As an example, 
consider a new polymorphic function $reverse$ that 
reverses the order of the elements in a list.
Recalling the formal specification for the polymorphic list type $\specL_{\alpha}$ (section \ref{sub:ListSpec}),
the specification for $reverse$ consists of an interface and these properties (figure \ref{reverse_spec_ex}).

\begin{figure*}
%\fbox {
\begin{minipage}[t]{.3\linewidth}
Axioms
\begin{align*}
& (type) : \\
& unit  property: \\
& involution property: \\
& concat property: 
\end{align*}
\end{minipage}
\begin{minipage}[t]{.1\linewidth}
\end{minipage}
\begin{minipage}[t]{.6\linewidth}
\begin{align*}
& reverse :  \specL_{\alpha} \ra \specL_{\alpha} \\
& \forall l \in \specL_{\alpha}.  reverse (cons(x, empty)) =_{\specL_{\alpha}} cons( x, empty) \\
& \forall l \in \specL_{\alpha}.     reverse (reverse(\ l\ ))  =_{\specL_{\alpha}}l \\
& \forall l_1,l_2 \in \specL_{\alpha} .  reverse(\ l_1 \concat\ l_2\ )  =_{\specL_{\alpha}} reverse( l_2 ) \concat reverse( l_1)
\end{align*}
\end{minipage}
%} % end xbox
\caption[Axioms for the reverse function.]
{An algebraic specification of a reverse function for the polymorphic list.}
\label{reverse_spec_ex}
\end{figure*}

\noindent This example specification is used throughout this section
to illustrate the different facets of \QC.

The example in figure \ref{reverse_prop_ex}  (\cite{Claessen2000}) shows 
the translation of the $reverse$ predicates
into Haskell properties (Boolean valued functions).

\begin{figure*}
\begin{code}
propRevUnitEq :: (Eq a) => a -> Bool
propRevUnitEq x = reverse (Cons x Nil) == (Cons x Nil)

propRevInvEq :: (Eq a) => List a -> Bool
propRevInvEq xs = (reverse.reverse) xs == xs

propRevConcatEq :: (Eq a) => List a ->  List a -> Bool
propRevConcatEq xs ys = reverse (xs ++ ys) == (reverse ys) ++ (reverse xs)
\end{code}
\caption[Haskell properties for the reverse function.]
{The Haskell properties of a reverse function for the polymorphic list.}
\label{reverse_prop_ex}
\end{figure*}

\noindent
Each of the three properties has a different domain:
unit of type |a|, involution |List a| and concatenation the pairs |(List a, List a)|.
In order to actually run a test for each of these, 
each must be assigned a concrete type,
for example replacing the |a| type variable with |Int|.
\QC must be able to generate the selected data types,
either using default generators supplied with the package (such as for |Int|),
generators built with the supplied combinators (such as the list generator combinator),
or custom built generators.

Concatenation is slightly different because
the property has two arguments and the property is implemented in its \emph{curried} form.
\QC treats curried properties as families of properties,
and tests a random selection of that family by
generating the first instance of the first argument, 
testing the property resulting from applying that argument as if it were a single argument property,
and repeating the process with additional instances of the first argument.
Alternately, the property could have been defined as

\begin{code}
propRevConcatEq :: (Eq a) => (List a, List a) -> Bool
propRevConcatEq (xs, ys) = reverse (xs ++ ys) == (reverse ys) ++ (reverse xs)
\end{code}

\noindent which would be treated as a property with a single input argument and 
require a generator for pairs of lists of type |a|.

If a property does not apply to all of the values of it's input type,
i.e. has an associated precondition,
the | (==>) | operator guards the equality so it is only tested with satisfactory values.
This is illustrated below with an example property called | propMax | (unrelated to reverse).
which is conditional on the first argument being less than the second;
test cases not satisfying this condition will be rejected from the test.

\begin{code}

max :: (Ord a) => a -> a -> Bool
propMax :: (Ord a) => (a, a) -> Property
propMax (x, y) = ( (x < y) ==> ( max x y == y) )

\end{code}

Conditional properties provide an important tool to practical test developement,
but also highlight a significant issue with syntax based automated test case generation.
A property will always have a parameter that is a valid type in the implementing language (in this case Haskell),
but that does not mean that every value of that type will be a valid input for that property.
In other words, the domain of the property may well be a proper subset of the values of it's input type.
This can be addressed in three ways:
\begin{itemize}
\item the test generator can be constructed to only provide valid test cases
\item the test program can filter out invalid test cases
\item the results of invalid test cases can be excluded from the verdict
\end{itemize}
This subject is addressed in chapter \ref{chap:requirements}.

\subsubsection{Test Program Interface}
The default invocation of \QC is through the |quickCheck| function,
supplying the property to be evaluated as input,
generating 100 random test values and returns ``OK'' if 
the property holds for all test cases or ``Falsifiable after $n$ tests''.
|quickCheck| is a call to the |check| function, 
supplying a set of default configuration values;
this approach of providing a general purpose function with
layers of defaulted parameters
is a standard technique in the implementation of programming interfaces,
allowing the user of the library to take as little or as much control of the settings
as their understanding and needs dictate.

|quickCheck|, |check| and the other related functions are instances of the | Testable | class,
guaranteeing a property that will compute a |Result| inside of the |Gen| monad.

\begin{lstlisting}
newtype Property = Prop (Gen Result)
newtype Gen a = Gen (Int -> StdGen -> a)
data Result  = Result { ok :: Maybe Bool, stamp :: [String], arguments :: [String] }
class Testable a where
    property = a -> Property
\end{lstlisting}

\noindent |Result| contains the test verdict, the classification of the test data,
and parameters used during the call to quickCheck.
A |Property| is a |Result| computation that occurs in a |Gen| monad,
which ensures that the unique seed (|StdGen|) values required for random generation
are threaded through the sequential computations.
Properties are encoded as |Testable| Haskell functions.
Typically a property is Boolean valued,
but \QC also supports conditional properties 
(i.e. the domain of the property is defined by its type
and an additional precondition) of type |Property|.

If the input type of a property is an instance of the |Arbitrary| class,
a \emph{generator} for that type exists (see below)
and so a default instance of Testable for that property.
The forAll operator combines a generator and 
a function that produces a |Testable| result into a |Property|.  
This automatic instance and the supplied default Arbitrary instances
hide the complexity of the interface for many common Haskell types,
allowing a user to invoke |quickCheck| 
without specifying or even knowing how the test cases are to be generated.

\begin{lstlisting}
forAll :: (Show a, Testable b) => Gen a -> (a -> b) -> Property
forAll gen body = Prop $
  do a   <- gen
     res <- evaluate (body a)
     return (argument a res)
 where
  argument a res = res{ arguments = show a : arguments res }

instance (Arbitrary a, Show a, Testable b) => Testable (a -> b) where
  property f = forAll arbitrary f

class Arbitrary a where
  arbitrary   :: Gen a
  coarbitrary :: a -> Gen b -> Gen b

\end{lstlisting}

\subsubsection{Generating Data}

Generators of test values of a type |a| are provided through 
the |arbitrary::Gen a| method from the |Arbitrary| class,
based on an integer size and random generator seed (|StdGen|).
Default generators for base types such as |Int| and |Char|
use Haskell's native random generators ,
and are also supplied for common structures such as (polymorphic) lists and tuples.
The |Arbitrary| class can optionally include a dual method |CoArbitrary|
to support the generation of ``random functions'' by 
creating random relations between inputs and outputs%
\footnote{A casual review of instances of Arbitrary provided by
packages available in the Hackage system revealed
few implementations of the coarbitrary method.}.

An |Arbitrary| instance must be provided for user defined algebraic data types.
A generator for an algebraic data type has a weight assigned 
to each of its data constructors.
When a term is generated, 
one of  the data constructors for the type is randomly selected based on that weighting,
and then its arguments are each generated using calls to |arbitrary|.
\GC relies on Haskell's class system to select the correct instance for that type.
This approach works for any algebraic data type, 
including recursive and mutually recursive systems, 
as long as all of the types involved are also instances of |Arbitrary|.

The generator functions are constructed using 
the \QC  product and disjoint union generator combinators.
Some of the provided combinators are:

\begin{description}
\item [oneof] provide an equal probability of picking from a list of constructors.
\item [frequency] specify a weighted probability of picking a constructor from a list.
\item [vector] generate a vector (list) of values of the type
\item [two, three, four] generate 2, 3 and 4 tuples (products) of one type
\end{description}

\noindent
For example, an instance of Arbitrary List can be constructed using 
the generator combinator |frequency|.
This allocates an integer weight to each of the constructors;
the probability a constructor is selected is its proportion of the total weight.
In this case, any given node will be the end of the list (Nil) only 1 out of 8 times,
or with a nominal probability of $12.5\%$.

\begin{code}
instance (Arbitrary a) => Arbitrary (List a) where
   arbitrary = 
          frequency [(1, Nil)
                    (7, liftM2 Cons arbitrary arbitrary]
\end{code}

This naive instance of |Arbitrary| is not guaranteed to terminate
in any given number of recursive iterations,
although the probability of generating any given list
is inversely proportional to its size.
\cite{Claessen2000} recommend explicitly terminating recursion after 
a maximum number of steps based on the size argument
(exposed by the |sized| combinator),
by supplying an internal definition of the generating function:

\begin{code}
instance (Arbitrary a) => Arbitrary (List a) where
   arbitrary = arbList
   
arbList = sized list'
list' 0 = return Nil
list' n | n>0 = 
         frequency [(1, Nil),
                    (7, liftM2 Cons arbitrary (list' (n-1))]
\end{code}

\noindent
This approach guarantees that the structure will be 
no larger than the requested size
which is exposed using the |sized| combinator.
Managing the termination explicitly adds to the complication
of developing \QC generators for recursive types,
and in particular mutually recursive structures.

\subsubsection{Test Execution}

During test evaluation, 
the |Gen| type wraps a function from a positive integer size and 
a Haskell |StdGen| seed value to the type being generated.
|Gen| is defined as a monad and is used to generate  a stream of random values
(although it is not a true monad as it does not satisfy the monad laws)
using the bind and return definitions to manage splitting and passing on the generating seed.
The | check | program binds a sequence of value requests,
passing the random generation seed,
and slowly incrementing the size parameter from 0 using a size modification function
(defaulting to |(+3).(`div` 2)|).
This provides a sampling of the property's domain,
stratified by the \emph{size} of the term,
which is the maximum recursive depth for an algebraic data type
(sizes are ignored for scalar / base types).

Test cases are generated and evaluated sequentially,
and the | check | program terminates:
\begin{enumerate}
\item on the first failed test case,
\item after the requested number of successful test cases are generated,
\item or after generating the maximum allowable test cases that did not satisfy the pre-condition.
\end{enumerate}
\noindent
The test is invoked in the Haskell IO monad,
to obtain a starting random seed (|StdGen|)
and ensure the tests evaluated despite Haskell's lazy evaluation model.

\subsubsection{Reporting}

The default report from a test declares either success and the number of test cases,
or failure, the failed case, and the number of successful tests before the failure.
The test results can be enhanced with
information about the test data values
by using the reporting combinators | collect |, | classify | and | trivial |.
These label and classify the test values used,
providing a simple coverage analysis, 
such as a count of test cases by size.

\begin{lstlisting}
propRevInvSized xs = collect (length xs)$ (reverse.reverse) xs == xs
	  where types = x::Int

Main> quickCheck propRevInvSized
OK, passed 100 tests.
18\% 0.
22\% 1.
13\% 2.
 8\% 3.
...

\end{lstlisting}

\noindent
This simplistic approach to coverage analysis
is suitable for the ``quick check'',
used to ensure a reasonable degree of variety in the test data set.

The test context for a \QC test is based on
testing cases of different sizes up to a maximum size.
This requires a regularity hypothesis to 
justify the maximum size (number of recursions) of the test cases,
and a stratification hypothesis to justify 
the selection of random cases from the domain stratified by size.
The definition of these assertions,
and the interpretation of the test verdict,
is left to the test developer.

\subsection{SmallCheck}\label{sub:easycheck}

\SC (\citep{Runcimanetal2008})  is based on \QC, 
but instead of randomly checking test values,
it exhaustively generates all simple, or ``small'', test values.
Because the two packages are so similar,
only the differences between them are mentioned here.

\subsubsection{Specification and Properties}
Formally, given a function |f| over a data-type |a|,
an exhaustive generator of instances of |a| up to a given ``depth'' (size), 
and a property |p| relating |a| and |f a| for all |a|,  
\SC verifies that | p | holds by creating all elements of | a | to that depth, evaluating | p | at those values.

There is a |Testable| class with |Property| encapsulating the test cases in a list monad
(as opposed to \QC's Gen monad).
The size parameter for generating test cases is explicitly exposed in \SC
as an argument of the property function (the |Int| is the size).

\begin{lstlisting}
data Result = Result {ok :: Maybe Bool, arguments :: [String]}
newtype PR = Prop [Result]
newtype Property = Property (Int -> PR)
	
class Testable a where
  property :: a -> Int -> PR

\end{lstlisting}

Properties are constructed in the same way,
using the |forAll| combinator to combine a test case generator and a | Testable | predicate.
The \SC package also introduces two new features for defining properties:

\begin{description}
\item [existential variables] tests that there is at least one value
within the specified depth that satisfies the property
\item [unique variables] test that there is \emph{only one} satisfactory value to the specified depth
\end{description}

\noindent Existential quantification in a property is a unique feature of \SC and \GAST as
it can be tested more effectively with a (partially) exhaustive testing strategy than 
with other sampling methods.

\subsubsection{Generating Data}
Exhaustive generators are instances of a class | Serial |, 
the analog of \QC 's |Arbitrary| class,
and provides a |series| method for generating lists of values
and |coseries| for generating function types.
The |Series| type encapsulates exhaustive data generation
of values of size $\leq n$, and is the analog of \QC's |Gen| monad.

\begin{lstlisting}

forAll :: (Show a, Testable b) => Series a -> (a->b) -> Property
forAll xs f = Property $ \d -> Prop $
  [ r{arguments = show x : arguments r}
  | x <- xs d, r <- evaluate (f x) d ]

instance (Serial a, Show a, Testable b) => Testable (a->b) where
  property f = f' where Property f' = forAll series f

type Series a = Int -> [a]
class Serial a where
  series   :: Series a
  coseries :: Series b -> Series (a->b)

\end{lstlisting}

Test case generators for algebraic data types can be constructed using the following combinators:

\begin{description}
\item [ $><$ ] |:: Series a -> Series b -> Series (a,b) | creates a generic product generator
\item [ cons0, cons1, etc.] creates generators for data constructors of 0, 1, ... arguments
\item [$\backslash/$] :: |Series a -> Series a -> Series a | creates a disjoint union generator
\end{description}

\noindent There are no weighted generator combinators like \QC's |frequency|
because exhaustive testing includes all of the test cases up to the specified size.

The Serial generator for List is given below as an example.
the simplicity of the interface is evident as the |cons| functions
hide the recursive calls to |series| in the generator.
\SC generators do not have the non-termination problem 
associated with the \QC constructive random generators,
so calling the default |series| method for the type is usually appropriate.

\begin{lstlisting}
instance Serial a => Serial (List a) where
  series = cons0 Nil \/ cons2 Cons
\end{lstlisting}

The interpretation of the \emph{size} of a type is very important
because it directly controls the size of the test suite:

\begin{itemize}
\item for structures, the size is the recursion depth
\item for based types that are instances of the Haskell (Enum) class,
the ``depth'' is interpreted as a range of values  | [ (-d) .. d ] |,
where $d$ is the size of the test case.
\end{itemize}

\noindent
All possible substitutions for each of the elements in a data structure
are made when populating algebraic data types 
defined over one or more type arguments.
The size of the element range is one less than the size of the node of the it occupies,
e.g. if the maximum depth is 4 and the node is at depth 2,
the elements will be |[-1,0,1]|.
All of the ``shapes'' up to the specified depth will be generated,
and the nodes will be populated by all permutations of 
the element values for each of the type arguments into each node of each structure.
This is the default interpretation of the composition of lists in Haskell,
so the implementation is straightforward.

Exhaustive testing by depth leads to an exponential increase in
the number of values when generating tree-like recursive algebraic data types,
because both the number of shapes and substitutions increases rapidly.
\SC provides additional combinators to reduce the size of the generated test suite
by altering the depth or filtering the generator lists,
but of course this makes the testing non-exhaustive.

\subsubsection{Interface and Reporting}

The | smallCheck :: (Testable a) => Int -> a -> IO () | function 
generates and tests all of the values of type |a| up to the specified maximum size
(recursion depth for recursive algebraic data types, a range for base types).
Other variants of the  | smallCheck | function 
allow the tester to decide to proceed to the next size,
or test only the values of a particular size.
The results of the test provide
the first failing case if one is found,
or the number of values successfully tested at each depth.
There is no parallel to the reporting combinators of \QC
because the expected strategy of using partially exhaustive testing
means the number of values tested at each depth is sufficient coverage analysis.
There is no way to determine the test data set
if the generators are filtered so not exhaustive.
%
\subsubsection{Test Execution}
%
| smallCheck | is run in the IO monad,
either from the command line or within a Haskell module.
The result is computed as a |map| of the property over the test data set,
a sequence of lists of test values from size 0 to the maximum depth;
this is implemented as a list comprehension
for most properties (those built over the qualifiers |forAll|, |exists|, or |exists1|).

The \SC test context is again stratified by
the complexity, or size, of the test cases,
but only requires the regularity hypothesis defining 
the maximum size necessary for the test
(or this could be considered a small scope hypothesis).
Since the test is exhaustive over the test cases up to that size,
the test context provides a ``proof'' of program correctness up to that complexity
(at least within the context of an idealized test),
so no stratification hypothesis is necessary.
The regularity hypothesis, however,
is generally much stronger for \SC than for \QC as
the maximum size of the test cases must generally be much smaller
to allow for exhaustive testing in a reasonable time.

\subsubsection{Lazy SmallCheck}

Lazy SmallCheck (\cite{Runcimanetal2008}) is similar to \SC but
works on partially evaluated structures.
It wraps values with a customized |Maybe| that 
identifies a value or a labelled ``hole'' in the structure of a test case, 
combined with a mechanism for filling the hole in the structure.
The result of a test is three possible values:
True, False or a test that can be evaluated over
a the test suite generated by substituting the possible values for that ``hole''.
This \emph{refinement}, or ``drill down'', procedure allows a test 
to terminate if the property is shown to fail over all instances that can be generated from the partial value,
thus avoiding the need to evaluate larger test cases.

There are some disadvantages to \LSC when compared to \SC.
It can be significantly more efficient that \SC,
but in situations where the property cannot benefit from the partial result, 
\LSC is actually less efficient than \SC because 
it creates  and evaluates the test over the partial values as well as the ``full'' ones.
It is restricted to operation on universally qualified properties,
as opposed to \SC which also supports existentially qualified variables,
and \LSC ties test evaluation and data generation more closely
in order to allow test cases to be generated from the partial cases.

\subsection{GAST}

The GAST project described in \cite{GAST2002} is an early version of 
generic automated software testing written,
with version written in both Clean and Haskell.
It is similar to \SC in using exhaustive testing of all values up to a specified size (complexity) as the default strategy,
and the input parameters for properties can be universally or existentially quantified,
but it differs in that it randomizes the order of the test cases
by randomly traversing left or right branches of disjoint unions. 
It uses a universal tree representation type descriptor 
to describe algebraic data types (e.g. the Haskell type constructor) and 
generic programming techniques to generate and execute tests.
An analysis function processes the list of results and provides a verdict for the test:

\begin{description}
\item [Proof] if all of the values in the domain of the property were exhaustively tested;
\item [Passed] if a test data set of the requested number of cases were tested successfully
but the test was not exhaustive; and
\item [Failed] if a counter example was found.
\end{description}

The authors justify exhaustive testing up to the specified size
by noting that a function typically contains 
special cases for the small elements of the input parameter type
and recursive cases for larger elements,
i.e. that the small scope hypothesis applies for algebraic properties.
A representative test data set should therefore have 
all of the small test cases and
a selection of larger values to test the more general cases, or equivalence classes.

Randomizing the order in which values from disjoint unions are generated
removes the order bias from a test data set.
This is important in \GAST test case selection because
the test generation is truncated at the size specified by the user,
and the randomization offers a broader diversity of values in any subset of
the partitions of the domain by size.
They also suggest that randomizing the order will
decrease the expected time to find an error in the test data set (should there be one),
which is important since \GAST terminates the test after finding an error.

\begin{quote}
Moreover, small values which appear close to the root of the generic tree have to be generated first. 
A depth-first traversal will encounter these values too late. 
Finally, a left-to-right strategy will favor values in the left branches and visa versa. 
A bias in any direction is undesirable.
In order to meet all these requirements, 
we use a strategy that uses a random choice at each EITHER in the type tree.
\end{quote}

There are a number of other similarities with \QC:
\begin{itemize}
\item a |forAll| combinator to identify universal quantification;
\item a |Testable| class providing an evaluation of properties 
when a test value generator is available;
\item the conditional implication operator, used to implement pre-conditions,
allows values of the input argument type to be excluded from the test suite 
\item provides reporting combinators to build into the properties that collect / classify test cases
\item uses a stream of random values to make left / right decisions at brand points,
so requires sequential (monadic) processing with a |Gen| like monad to manage the random seed values
\end{itemize}

The authors recognized that generating test cases from 
base types with large sets of  values 
posed a particular challenge in developing efficient tests.
They recommend the use of a \emph{hybrid sampling strategy}
combining exhaustive, boundary and random value generation
(and accepting duplicate values).
%\begin{quote}
%``For finite types like Bool or non-recursive algebraic datatypes 
%we can generate all elements of the type as test-data. 
%For basic types like Real and Int, generating all elements is not feasible. 
%There are far too many elements...
%For these types, we want GAST to generate some common border values, like 0 and 1, 
%as well as random values of the type. 
%Here, preventing duplicates is usually more work than repeating the test. 
%Hence we do not require that Gast prevents duplicates here.''
%\end{quote}
%
%\noindent 
GAST also includes combinators to pull in user supplied test cases,
which seems an obvious addition but is not available in the other packages.
The test data set is truncated to the number of cases requested by the tester,
resulting in an incomplete sample of the stratum of the largest cases tested.
As a result, the test context for \GAST is similar to that of \SC,
but the regularity hypothesis may need to be supplemented by
a stratification hypothesis supporting the partial (truncated random) sampling
of the stratum of the largest test cases.

\subsection{EasyCheck}

EasyCheck (\cite{EasyCheck2008}) is written in Curry, 
and uses Curry's built in narrowing and data refinement to generate test cases.
This provides support for testing partially defined values
and terminating the testing of a particular branch of an algebraic data type if
the property can be conclusively evaluated with just that partial type,
as found in \LSC.
Curry provides support for non-deterministic types and free variables,
encapsulating the non-determinism in a ``search tree'' to provide order to the choices.
Test evaluating is based on refining and expanding the ``search tree'' that
implicitly defines an enumeration over the non-deterministic choices provided by the free variable or type.
Test inputs are defined in the same way as \QC and \SC,
but the selection process takes the diagonal from the enumeration across the branches,
randomizing the selection order of the branches.
This provides a balance between small and large tree-like structures
earlier in the order of the test cases
than the other packages which generate the test cases in order of size (complexity).

The default enumeration provided by Curry is modified by \EC with the goal of
establishing what the authors describe as a \emph{complete, balanced and advancing enumeration}:

\begin{df}[Enumeration Properties  (\cite{EasyCheck2008})]
An enumeration of the values of a type in Curry is :

\begin{description}
\item[complete] if every value is eventually enumerated.
\item[advancing] in order to avoid numerous trivial test cases,
the first node of the $n^{th}$ level of a search tree must have an enumeration index
of less than p(n) where p is a polynomial. 
\item[balanced] if the enumerated values are independent of 
the order of child trees in branch nodes
\end{description}

\end{df}

\noindent Diagonalizing the search trees into a list
that encapsulates the total ordering of the test values 
provides the complete, balanced, advancing enumeration.
The use of the enumeration is fundamental to the EasyCheck testing strategy,
providing the basis for selecting representative test cases from 
anticipated equivalence classes of the test domain.
The authors also note that more work is required to
find an efficient enumeration scheme that is complete, balanced and 
generates sufficiently diverse large test values \emph{early} in the test data set.
This complete, balanced, advancing enumeration is 
the supporting stratification hypothesis for the text context,
which is completed by a regularity hypothesis.
%\begin{quote}
%Finding an efficient enumeration scheme that is complete, balanced and 
%generates sufficiently different large values \emph{early} deserves future work.
%\end{quote}

\subsection{Functional Enumeration of Algebraic Types (FEAT)}

Functional Enumeration of Algebraic Types, or \FEAT, was introduced in \cite{Duregard2012}.
The interface is loosely based on \QC and \SC
and provides similar functionality,
but test data can be either randomly, 
uniformly or exhaustively generated (see section \ref{sec:sampling_theory} for definitions) .
It explicitly provides both ranked and base \emph{enumerations} of Haskell types,
as described in section \ref{sec:enumerations},
providing the number of values (count function),
an order (index function) and a selection function that produces the value at any given index.
For recursively defined algebraic data types
the values are partitioned by size,
which is defined to be the total number of \emph{data constructors} in the term.

\FEAT uses a \emph{selective} approach to random sampling,
as opposed to \QC's \emph{constructive} approach,
basing the selection on an \emph{enumeration} of the types values.
The enumeration specifies the number of structures of a given size,
and so allows a uniform probability distribution for
randomly selecting elements.
This is consistent with the stratified sampling methods discussed in section \ref{sec:sampling_theory}
and the use of \emph{enumerative generators} discussed in section \ref{sec:enumerations}.
Random samples are evaluated as instances of the \QC |Gen| monad,
providing a high degree of compatibility.
Exhaustive and uniformly selected (i.e. every $k^{th}$ value from the index) test data sets
are evaluated using the Haskell |map| function, as in \SC;
this use of separate monads precludes hybrid sampling methods.
The test context is the same as \QC or \SC, respectively.

The focus of the \FEAT package is providing efficient 
and easily implemented enumerations of Haskell types .
The performance is enhanced by extensive optimizations,
including \emph{memoization} of the count, index and select functions.
They claim their enumerations are faster for generating large exhaustive samples than \SC
(some empirical evidence of this is provided in the paper).
They also claim they are easier for test developers to write than \QC generators,
particularly for mutually recursive types.

%Authors notes:
%"We argue that functional enumeration is the only available option for automatically generating useful test cases from large groups of mutually recursive syntax tree types. Since compilers are a very common application of Haskell, Feat fills an important gap left by existing tools."
%"However, it is well known that reasonable QuickCheck generators are really difficult to write for mutually recursive datatypes (such as syntax trees) ï¿½ sometimes the generator grows as complex as the code to be tested! SmallCheck generators are easier to write, but fail to falsify some properties that Feat can."
%"A noticeable feature of Feat is that it pro- vides random sampling with uniform distribution over a size- bounded subset of a type. This is not just nice for compatibility with QuickCheck, it is genuinely difficult to write a uniform gener- ator even for simple recursive types with the tools provided by the QuickCheck library."

\subsection {Comparison}

These  packages share many characteristics,
some of which should be included in any property based testing package,
while others seem to be weaknesses despite appearing in all of the packages.

The use of properties as the basis for the testing is simple, useful and popular.
The |Property| type in \QC, \SC, and \GAST is used to 
abstract the test result to allow 
additional information to be stored along with the pass / fail verdict.
The specification axioms are initially encoded as a Boolean valued functions,
as expected, but the |Property| type is actually 
a |Result| type embedded in the execution strategy.
This introduces  a number of weaknesses in the implementations
(as opposed to the concept):

\begin{enumerate}
\item it encapsulates the collection of test results but does not include the tested values;
\item the reporting is embedded in the property so it is necessary to rewrite 
the property function to change the coverage analysis;
\item the test generation functions are tightly coupled with the execution monad 
(e.g. the |Gen| monad for \QC, the list monad for \GAST and \SC, 
or the non-determinisic enumeration of \EC) so 
that it is difficult to add, combine or modify the sampling methods within the package.
\end{enumerate}

All of the packages assume a sequential model of test execution,
with the test terminating after the first failure.
Newer versions of \QC allow multiple failures before termination,
but still assume the tests are running sequentially.
Test cases are generated as needed by a \emph{monadic} test evaluator:

\begin{description}
\item [QuickCheck] uses the Gen monad to sequentially generate and evaluate random samples,
\item [SmallCheck, GAST] uses the list monad to order test cases of each depth,
\item [Lazy SmallCheck] uses a custom monad to manage the injection
of simulated partial values and then refine those values,
\item [EasyCheck] uses Curry's monad-like non-deterministic free variables and search trees
to generate and order the test cases,
\item[\FEAT] evaluates test cases in either the list or |Gen| monad,
depending on the sampling method used
(although the enumerations were developed so that
they could be computed in parallel to some extent)
\end{description}

Serializing the order of test case evaluation and 
terminating with the first (or $n_{th}$) error
may be efficient during the early, debugging stage of  the development process,
but:

\begin{itemize}
\item in general, the ordering of the test cases is only a heuristic
to improve the probability that an error will be found early in the test suite;
\item identifying more failing test cases might make fixing the program easier;
\item reporting errors as they occur but continuing to test
until the test is interrupted is clearly a superior solution with little or no impact on the program architecture
\end{itemize}

As the development cycle nears the end,
the focus of the test shifts to collecting and presenting evidence of program correctness,
and so achieving better coverage through more test cases and better reporting becomes the priority.
A ``quick check'' of a simple property is well served by a linear test,
but in later stages of development with much larger test suites,
concurrent test evaluation (with time limits to catch non-terminating test cases) is appropriate.
The packages combine three activities that could be de-coupled:

\begin{enumerate}
\item generating a test set
\item evaluation of properties over a test set
\item providing an appropriate report of the test results to support coverage analysis
\end{enumerate}

\noindent
Since one of the fundamental axioms of testing is that the test cases are independent,
there is no activity better suited to parallel execution than testing.
The increasing availability of multi-processor, multi-core, and multi-system (cloud) platforms
should be considered an opportunity to greatly increase the resources available for testing.
\SC, \GAST and \FEAT use Haskell's |map| function to evaluate test cases,
which might be amenable to a concurrent implementation 
(for example using parallel Haskell),
but the use of the |Gen| monad to carry the seed for the random generators
effectively locks \QC and \FEAT into sequential evaluation.
Decoupling the test case generation and execution would permit
a simple sequential model of test evaluation during the early phases of development,
with a transition to more sophisticated reporting and concurrent test evaluation
using the same properties and test case generation.

The strongest feature of these packages is their ability generate test data.
All provide a \emph{test case generator language}, 
using a datatype generic programming strategy based on 
universal descriptions of algebraic data types
to define generator functions.
Generators for base types and common structures are provided with each package,
with generators for user defined types built from 
combinators for disjoint unions and products of component type generators.
The combinators mirror the type constructor algebra,
so generators can be created (mostly) mechanically from the type definition
(instances of the \QC |Arbitrary| class can be generated using DrIFT for example,
although these instances do not provide the 
modifications required to guarantee termination).
These are accessed through the class system,
which makes building structures with polymorphic arguments seamless.
This approach supports creating generators for most Haskell (regular polynomial) types,
that should form the core of any property based testing for Haskell or other functional language.

All of the packages consider the size, or complexity,
of the test cases to be a controlling factor in
the selection and ordering of test cases,
prioritizing the smaller test cases over the larger.
The size variable acts as a measure of complexity
compatible with use of the regularity hypothesis (section \ref{sub:regularlity}),
and the small scope hypothesis (definition \ref{def:smallscope}).
\FEAT uses the total number of constructors in a value as it's size,
while the other packages use the maximum recursion depth of the structure as the size.
Using the total number of constructors instead of the maximum branch depth
avoids a left-weighting bias caused by structure composition,
(which will be discussed in \ref{sec:enumerations}).
In \cite{Duregard2012}, the authors present the results of an experiment
comparing the \SC and \FEAT approach to 
exhaustively generating a complex data type (the Haskell AST),
and demonstrate that \FEAT produces a more appropriate distribution of test cases
\footnote{They specifically note that 
"SmallCheck tends to get stuck in a corner of the space and test large but similar values".}.
It is unclear which of these complexity measures will provide a superior test suite
when used as the basis for stratified sampling.

The interpretation of size for types other than recursive tree-like structures
is different between the packages.
\QC and \EC ignore  size when generating base types,
while \SC and \LSC generate a list of base type values  
bounded above and below by the size
(i.e. $\left(-d,d\right)$ for enumerated (Haskell class |Enum|) base types like |Int|).
\FEAT enumerates base types and extends the enumeration of
any type incorporating them to include that enumeration
(potentially creating unmanageable enumerations in the process).
\GAST does not provide generators for base types,
but suggests (\cite{GAST2002}) that a combination of extreme and random values 
are used for test cases.
While these disparate approaches do not offer much guidance
(the generation of base types seems to largely be an afterthought),
this last suggestion seems to provide the most appropriate direction.
This is particularly evident in exhaustive (or uniform interval) sampling,
where it is unclear what advantage is gained by sampling a small compact interval
of the values of a base type in each position in a recursive tree-like structure.
Providing distinct or hybrid sampling methods for base and recursively defined types
would allow much more efficient test data sets to be generated.

All of the papers agree that automated test case generation is important for
performing tedious, mundane task of generating tests,
and all focus on the way in which test cases are selected and ordered.
Each package uses the size of recursive structures as the basis for generation,
and all except \FEAT provides a single sampling method for test case selection.
Even \FEAT, which supports multiple sampling strategies for test case generation,
does not allow different sampling methods to be used in a single generator,
and cannot because the test evaluations are through distinct monadic evaluators.

While the packages can be used independently to complement each other,
especially since the properties are defined in the same way,
it seems that it would be more appropriate to allow
multiple sampling methods to be combined into 
a common strategy for test case generation
in a single test package.
Earlier work by Uszkay and Carette (presented at IFL 2009 but not published)
showed that \QC and \SC could be effectively merged
allowed exhaustive and random test generation
of the different components of a common type
(e.g. exhaustively generating heaps trees up to a depth of 3, 
but with random integer nodes)
by merging the |Gen| and list monads,
but even this was locked to two sampling methods.
Test developers should be free to combine different sampling methods into test case generators without arbitrary restrictions to support test case evaluation.

All of the packages provide a limited ability to
perform an analysis of the coverage provided by the test cases they generate.
The test programs provide the report of the test result through Haskell's IO monad (or equivalent IO facility).
\QC provides the |trivial|, |collect| and |classify| functions which 
count size 0 cases, test cases of each size, 
and categorize results in a user defined scene respectively.
This is a good but minimal set of report combinators,
suitable for a ``quick check'' but might not provide enough information
about the successful test result to justify a conclusion of program correctness
in more complicated situations.
While generally the strategy of exhaustive testing 
to a given depth used by \SC is self-explanatory,
if the test suite is modified with filters there is no easy way to get coverage analysis;
similarly in \LSC there is no way to know how many test cases were resolved 
through partial evaluations.
\EC and \GAST randomize the order in which test cases are selected
and then truncate the test data set at the requested number of elements,
so it is difficult to determine which values were \emph{not} selected.
\FEAT does not address the issue of coverage analysis.

The authors of \QC acknowledge the weaknesses of the reporting explicitly:

\begin{quote} 
The major limitation of QuickCheck is that there is no measurement of test coverage. (\cite{Claessen2000})
\end{quote}

\noindent
As an example of a problem caused by the lack of coverage analysis, 
both \cite{Claessen2000} and \cite{EasyCheck2008} provide (different) examples
of a test for an insertion function that requires a valid input collection
(a sorted list and a valid heap, resp.).
If a conditional property is tested over a collection of valid and invalid inputs, 
rejecting the invalid cases as part of the test,
the resulting test suite is very heavily slated towards small test cases as 
the arbitrary larger test cases are significantly less likely to be valid.  
Ideally, the tester would write a generator that produces only valid collections
to avoid the bias introduced by filtering,
but the test report must provide sufficient coverage information to identify the problem.
Reporting and coverage analysis was not a significant part of any of the packages,
perhaps appropriately given the nature of the work done by the Haskell community,
but production software testing environments will require
much more sophisticated coverage analysis and reporting tools.

\subsection{Summary}
One of the most attractive features of these systems is that
they require relatively little effort to learn
(\FEAT is arguably more complicated),
are easy to use, and provide results quite quickly.
Even given the different implementation languages and generating strategies, 
these packages share a number of traits:

\begin{enumerate}
\item test individual properties encoded as Boolean valued functions,
\item allow properties to be \emph{polymorphically typed}
\item support \emph{automatic test case generation} based on the property type,
\item \emph{tightly integrate} test case generation with test execution and reporting,
\item provide a \emph{test data generation language} for building test case generating functions,
\item allow default test value generators to be \emph{mechanically derived} from 
the input type of the property, and
\item allow test case generators to be \emph{customized} by the test developer.
\end{enumerate}

\noindent 
The consensus of the packages on the definition of properties and
the use of Haskell classes for integrating generators of different types
suggests that these aspects of their design is appropriate
for any property based testing tools.

The most significant conclusion to be drawn from the differences 
is that the different \emph{sampling strategies} are clearly the focus of research in this area,
but there is little basis to support direct comparison except experimentation.
Given this lack of certainty,
a \pbt system should allow test developers to 
use different sampling methodologies,
and develop new (or hybrid) testing strategies without
requiring the development of an entirely new software package.
The tight coupling of evaluation, reporting and generator functions
prevents this mixing of sampling methodologies,
and also ties the user into a single (sequential) mode of evaluation
and a simple reporting system.
This thesis will demonstrate that these restrictions are unnecessary
and that \pbt systems of this nature can provide a great deal of flexibility
without giving up the usability of the \QC interface.

